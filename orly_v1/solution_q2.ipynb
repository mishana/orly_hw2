{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Homework 1 - Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:37.795065Z",
     "start_time": "2021-11-20T00:55:36.390586Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# inline plot\n",
    "%matplotlib inline\n",
    "# default figure size\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 10)\n",
    "# to make our sets reproducible\n",
    "np.random.seed(42)\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:37.810120Z",
     "start_time": "2021-11-20T00:55:37.798631Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:37.854450Z",
     "start_time": "2021-11-20T00:55:37.816042Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_path = Path('..') / 'data' / 'data2.parquet'\n",
    "t = pq.read_table(data_path, memory_map=True)\n",
    "df = t.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### First Impressions - basic visual analysis of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some basic statistics on the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:37.885357Z",
     "start_time": "2021-11-20T00:55:37.860168Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There is a clear increase in the variance of $y$ as $x$ increases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:38.243185Z",
     "start_time": "2021-11-20T00:55:37.892721Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.plot.scatter(x='x', y='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract $X$ and $y$ into arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:38.262889Z",
     "start_time": "2021-11-20T00:55:38.255205Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X = df.x.values.reshape(-1, 1)\n",
    "y = df.y.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us find out what a simple linear regression produces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:38.400634Z",
     "start_time": "2021-11-20T00:55:38.267683Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# include intercept\n",
    "lin_reg = LinearRegression(fit_intercept=True)\n",
    "lin_reg.fit(X, y)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the linear function - obtained from linear regression, along with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:38.608644Z",
     "start_time": "2021-11-20T00:55:38.406307Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(X, y, \"b.\")\n",
    "\n",
    "xs = np.linspace(int(X.min()), int(X.max()), 100)[:, np.newaxis]\n",
    "ys = lin_reg.predict(xs)\n",
    "plt.plot(xs, ys, \"g-\", label='fit')\n",
    "plt.title('Linear Regression model')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Let us check if linear regression assumptions hold true:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### First, we analyze the 'Residuals vs. Fitted' plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:38.848299Z",
     "start_time": "2021-11-20T00:55:38.614937Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = lin_reg.predict(X)\n",
    "\n",
    "residuals = y_predicted - y\n",
    "plt.scatter(x=y_predicted, y=residuals)\n",
    "plt.title('Residuals vs. Fitted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "There is a funnel-shaped pattern evident in the 'Residuals vs. Fitted' scatter plot. This suggests non-constant variance, that is, Heteroskedasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:38.875389Z",
     "start_time": "2021-11-20T00:55:38.860959Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.stattools import durbin_watson\n",
    "durbin_watson(residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We see that the Durbin - Watson (DW) statistic is > 2 and < 4. Which indicates there is a negative autocorrelation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let us analyze the Normal Quantile-Quantile (Q-Q) plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:39.073704Z",
     "start_time": "2021-11-20T00:55:38.884601Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import probplot\n",
    "\n",
    "_ = probplot(residuals, plot=plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This looks not as normal as we'd like, especially in the higher and lower \"theoretical quantiles\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### We conclude that the residuals do not admit linear regression assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let us model the data using quantile regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Quantile Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:39.199519Z",
     "start_time": "2021-11-20T00:55:39.087124Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "quant_reg = smf.quantreg(formula='y ~ x', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let us model quantile regression on the data with quantiles in 0.05, 0.5 and 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:39.255062Z",
     "start_time": "2021-11-20T00:55:39.201224Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "q_5 = quant_reg.fit(q=0.05)\n",
    "q_median = quant_reg.fit(q=0.5)\n",
    "q_95 = quant_reg.fit(q=0.95)\n",
    "\n",
    "print(q_5.summary())\n",
    "print(q_median.summary())\n",
    "print(q_95.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, let us compare the results with linear regression and analyze them visually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:39.481349Z",
     "start_time": "2021-11-20T00:55:39.259543Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "\n",
    "xs = np.linspace(int(X.min()), int(X.max()), 100)[:, np.newaxis]\n",
    "\n",
    "ys_lin = lin_reg.predict(xs)\n",
    "\n",
    "ys_quan_5 = q_5.params['Intercept'] + q_5.params['x'] * xs\n",
    "ys_quan_median = q_median.params['Intercept'] + q_median.params['x'] * xs\n",
    "ys_quan_95 = q_95.params['Intercept'] + q_95.params['x'] * xs\n",
    "\n",
    "plt.plot(xs, ys, \"g-\", label='Linear Regression')\n",
    "\n",
    "plt.plot(xs, ys_quan_5, linestyle='dotted', color='grey', label='q = 0.05')\n",
    "plt.plot(xs, ys_quan_median, linestyle='dotted', color='orange', label='q = 0.5')\n",
    "plt.plot(xs, ys_quan_95, linestyle='dotted', color='red', label='q = 0.95')\n",
    "\n",
    "plt.title('Linear Regression vs. Quantile Regression')\n",
    "plt.legend(loc='best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Some conclusions from the plots:\n",
    "1. For low quantiles - y decreases with x (negative slope). For high quantiles - y increases with x (positive slope).\n",
    "2. The dispersion of y increases with x.\n",
    "3. The linear regression estimate is very close to the median quantile estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The other interesting visualization is slope values and their upper/lower bounds (confidence intervals) for different quantiles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "First, let us use the statsmodels package to model the data with least squares (linear regression) and extract upper/lower bounds of confidence levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:39.507937Z",
     "start_time": "2021-11-20T00:55:39.493935Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ols = smf.ols('y ~ x', df).fit()\n",
    "ols_lb, ols_ub = ols.conf_int().loc['x'].tolist()\n",
    "ols_intercept = ols.params['Intercept']\n",
    "ols_coeff = ols.params['x']\n",
    "\n",
    "# just make sure - sanity check\n",
    "assert np.allclose(ols_intercept, lin_reg.intercept_)\n",
    "assert np.allclose(ols_coeff, lin_reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-20T00:55:39.765790Z",
     "start_time": "2021-11-20T00:55:39.509657Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "qs = [0.05, 0.5, 0.95]\n",
    "\n",
    "q_5_lb, q_5_ub = q_5.conf_int().loc[\"x\"].tolist()\n",
    "q_median_lb, q_median_ub = q_median.conf_int().loc[\"x\"].tolist()\n",
    "q_95_lb, q_95_ub = q_95.conf_int().loc[\"x\"].tolist()\n",
    "\n",
    "plt.plot(qs, [q_5.params['x'], q_median.params['x'], q_95.params['x']], color=\"black\", label=\"Quantile Reg.\")\n",
    "plt.plot(qs, [q_5_lb, q_median_lb, q_95_lb], color=\"black\", linestyle=\"dotted\")\n",
    "plt.plot(qs, [q_5_ub, q_median_ub, q_95_ub], color=\"black\", linestyle=\"dotted\")\n",
    "plt.plot(qs, [ols_coeff] * len(qs), color=\"red\", label=\"OLS (Linear Reg.)\")\n",
    "plt.plot(qs, [ols_lb] * len(qs), linestyle=\"dotted\", color=\"red\")\n",
    "plt.plot(qs, [ols_ub] * len(qs), linestyle=\"dotted\", color=\"red\")\n",
    "plt.ylabel(r\"slope\")\n",
    "plt.xlabel(\"Quantiles of y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The above plot shows the variation of slope across different quantiles and comparison with ordinary linear regression, which is flat across all the quantiles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In most cases, the quantile regression point estimates lie outside the OLS confidence interval, which suggests that the effect of x on y may not be constant across the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Quantile Regression - what is it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Standard linear regression uses the method of least squares (or MSE) to calculate the conditional mean of $y$ across different values of $x$.\n",
    "Quantile regression is an extension of Standard linear regression, which estimates the conditional median (which is the 50th quantile, as well as other quantiles) of $y$\n",
    "and can be used when assumptions of linear regression are not met (i.e., linearity, homoscedasticity, independence, or normality)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "##### Fitting Quantile Regression models:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The standard linear regression model for the conditional mean of $y$ is:\n",
    "$MSE = \\frac{1}{n} \\cdot \\sum_{i=1}^n (y_i - \\beta^\\intercal \\cdot x_i)$\n",
    "\n",
    "In contrast, the regression model for quantile level $\\tau$ of $y$ is:\n",
    "$MAD = \\sum_{i=1}^n \\rho_{\\tau} (y_i - \\beta(\\tau)^\\intercal \\cdot x_i)$\n",
    "where $\\beta(\\tau)$ is now a function of the quantile parameter $\\tau$ and $\\rho_{\\tau}(r) = \\tau \\cdot \\operatorname{max}(r, 0) + (1 - \\tau) \\cdot \\operatorname{max}(-r, 0)$ is referred to as the check loss, as its shape resembles a check mark."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Quantile Regression - when to use it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. To estimate the median, or the 0.25 quantile, or any quantile\n",
    "2. Key assumption of linear regression is not satisfied\n",
    "3. Outliers in the data\n",
    "4. residuals are not normal\n",
    "5. Increase in error variance with increase in outcome variable"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
