{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Assignment 1 - Q2 - Quantile Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# inline plot\n",
    "%matplotlib inline\n",
    "# default figure size\n",
    "matplotlib.rcParams['figure.figsize'] = (20, 10)\n",
    "# to make our sets reproducible\n",
    "np.random.seed(42)\n",
    "%config Completer.use_jedi = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "first, read the .parquet file using pyarrow and then convert to a pandas DataFrame"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from pathlib import Path\n",
    "\n",
    "data_path = Path('..') / 'data' / 'data2.parquet'  # assume there is a data folder in the parent path\n",
    "data = pq.read_table(data_path, memory_map=True)\n",
    "data = data.to_pandas()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "analyze the data by sampling and visually in a scatter plot. look for outliers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.plot.scatter('x', 'y', title='data scattter plot with outliers')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we notice that the variance on the response variable y increases with x, and this is something linear regression won't be able to model,\n",
    "as it only models the conditional mean of y on x."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "now, try and fit a simple linear regressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "# include intercept\n",
    "lin_reg = LinearRegression(fit_intercept=True)\n",
    "lin_reg.fit(data.x.values.reshape(-1, 1), data.y)\n",
    "f'y = {lin_reg.intercept_} + {lin_reg.coef_[0]} * x'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.plot.scatter('x', 'y', title='data scatter plot and simple linear regressor', label='data')\n",
    "\n",
    "plt.plot(data.x, lin_reg.predict(data.x.values.reshape(-1, 1)), \"g-\", label='simple linear regressor')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "are the assumptions of linear regression correct? let's check it out."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "residuals = lin_reg.predict(data.x.values.reshape(-1, 1)) - data.y\n",
    "plt.scatter(x=lin_reg.predict(data.x.values.reshape(-1, 1)), y=residuals)\n",
    "plt.title('Residuals vs. Fitted')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "there's an obvious pattern of a funnel shape, we consider this as a sign of non constant variance, i.e., heteroskedasticity."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "perform a Shapiro-Wilks test to determine if the residuals are normally distributed"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from scipy.stats import shapiro\n",
    "\n",
    "shapiro(residuals)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "from the output we can see that the test statistic is 0.9594 and the corresponding p-value is 0.003, which is much lower than the usual cut-off p-value of 0.05. since the p-value is less than .05, we successfully reject the null hypothesis. we have sufficient evidence to say that the sample data does not come from a normal distribution.\n",
    "meaning, the residuals do not seem normally distributed."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we conclude that the residuals do not meet linear regression key assumptions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "now about Quantile Regression:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quantile regression is an extension of standard linear regression, which estimates the conditional median of the outcome variable and can be used if the assumptions of linear regression do not hold true.\n",
    "Although quantile regression is most often used to model specific conditional quantiles of the response, its full potential\n",
    "lies in modeling the entire conditional distribution. By comparison, standard linear regression models only the\n",
    "conditional mean of the response and is computationally less expensive. Quantile regression does not assume a\n",
    "particular parametric distribution for the response, nor does it assume a constant variance for the response, unlike\n",
    "linear regression.\n",
    "Meaning, linear regression for a response $Y$ and a predictor $X$ models the conditional mean $E[Y | X]$, but it does not\n",
    "capture the conditional variance $Var[Y | X]$, much less the conditional distribution of Y given X."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "By fitting a series of regression models for a grid of values of $\\tau$ in the interval (0,1), you can describe the entire\n",
    "conditional distribution of the response. The optimal grid choice depends on the data, and the more data you have,\n",
    "the more detail you can capture in the conditional distribution."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The main advantages of quantile regression are:\n",
    "1. Predicts conditional quantiles instead of just the conditional mean.\n",
    "2. Unlike linear regression, it is distribution agnostic (no normality assumption).\n",
    "3. It is robust to response outliers."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "let's compare linear and quantile regression on our data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import quantreg, ols\n",
    "\n",
    "# simple linear regression with least squares\n",
    "ols_model = ols('y ~ x', data).fit()\n",
    "confidence_interval = ols_model.conf_int().loc['x'].tolist()\n",
    "ols_params = {'intercept': ols_model.params['Intercept'], 'slope': ols_model.params['x'], 'conf_int': confidence_interval}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "quantiles = [0.05, 0.5, 0.95]\n",
    "# fit a quantile regression model for each quantile\n",
    "qreg = quantreg('y ~ x', data)\n",
    "quantreg_models = [qreg.fit(q) for q in quantiles]\n",
    "confidence_intervals = [quantreg_model.conf_int().loc['x'].tolist() for quantreg_model in quantreg_models]\n",
    "quantreg_params = [{'intercept': quantreg_model.params['Intercept'], 'slope': quantreg_model.params['x'], 'conf_int': confidence_interval} for quantreg_model, confidence_interval in zip(quantreg_models, confidence_intervals)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "plot 1: we compare standard linear regression estimate with quantile regression estimates, per each quantile."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data.plot.scatter('x', 'y')\n",
    "\n",
    "x = np.linspace(int(data.x.min()), int(data.x.max()), 200).reshape(-1, 1)\n",
    "# linear regression line\n",
    "y_linear = lin_reg.predict(x)\n",
    "plt.plot(x, y_linear, \"r-\", label='Linear Regression')\n",
    "\n",
    "for q, q_params in zip(quantiles, quantreg_params):\n",
    "    plt.plot(x, q_params['intercept'] + q_params['slope'] * x, linestyle='dotted', color='grey')\n",
    "\n",
    "plt.title('Linear Regression vs. Quantile Regression')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "note the negative slope for lower quantiles and positive slope for higher quantiles. also, the mean estimator (standard linear regression) and the median estimator (quantile = 0.5) are close."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "plot 2: we plot the slope at different quantiles with confidence intervals. note that the slope of linear regression is constant (by definition) and is presented for reference as well."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(quantiles, [ols_params['slope'] for _ in quantiles], color=\"red\", label=\"OLS (Linear Regression)\")\n",
    "plt.plot(quantiles, [ols_params['conf_int'][0] for _ in quantiles], linestyle=\"dotted\", color=\"red\")\n",
    "plt.plot(quantiles, [ols_params['conf_int'][1] for _ in quantiles], linestyle=\"dotted\", color=\"red\")\n",
    "\n",
    "plt.plot(quantiles, [q_params['slope'] for q_params in quantreg_params], color=\"black\", label=\"Quantile Regression\")\n",
    "plt.plot(quantiles, [q_params['conf_int'][0] for q_params in quantreg_params], color=\"black\", linestyle=\"dotted\")\n",
    "plt.plot(quantiles, [q_params['conf_int'][1] for q_params in quantreg_params], color=\"black\", linestyle=\"dotted\")\n",
    "\n",
    "plt.ylabel(r\"Slope\")\n",
    "plt.xlabel(\"Quantiles of y\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "we see that for low and for high quantiles, the quantile regression slopes are far outside of the linear regression confidence intervals.\n",
    "this probably indicates a non-constant connection between x and y variables, across the distribution of y."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}